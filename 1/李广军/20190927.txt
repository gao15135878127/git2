什么是自然语言
NLP的研究内容：
信息检索
舆情分析
文档分类
文本挖掘
文本匹配
人类语言主要是离散的/符号的/

为什么NLP难

场景困难：语言多样性，上下文（语境）。多变性，歧义性。
语料：什么是预料，预料作用，如何获得预料

重复学习是很重要的
自然语言发展趋势很好。

******做一些务实可行性比较强的事物

谁说的话听一半，要有自己的判断

NLP表示层次：形态级别
NLP工具：句法分析
今天主学习的是文本表示
1、文本表示概述
      文本表示简单的理解就是将字符串用向量表示出来。

      为什么要进行文本表示？
            最重要的就是便于计算机处理。  

2、文本离散表示
      文本表示分类
            基于粒度（就是根据所占空间大小划分）:
                  长文本表示
                  短文本表示
                  词表示
            基于表示方法：
                  离散表示：
                        One-hot表示：就是将词在词袋中的位置用其索引表示出来。不考虑词与词之间的关系。也不考虑词与句子之间的联系。
                        Bag of Words(词袋子模型):就是将不同的文本拆成词，分别放入不同的词袋子中，然后，只比较相同词的数量，来判定句子的相似度。
                              优点：简单、方便、快速，在语料充足的前提下对于简单的自然语言处理任务效果不错。
                              缺点：精准率低，不能体现不同词在语句中的重要性，无法关注词语之间的顺序。
                        TF-IDF：各个词向量的一个加和，考虑了词在句子中的出现次数，没有考虑词的顺序。
                        Bi-gram和Ni-gram：考虑词之间顺序，到那时此表会膨胀。
                        离散表示：最大问题是难以捕捉文本含义，无法衡量词向量之间的关系和数据稀疏性问题。
                  
3、文本分布式表示
      分布式表示：
             优势就是将向量乘法改成加法，用一个词附近的其他词来表示该次。
             共现矩阵：将文本中的词取出作为表的行和列，其中的数据是该词后边出现其他词的次数。(讲共现矩阵作为词向量)
                   优点：可以体现出词与词之间的顺序。
                   缺点：向量维数随着词典增加呈线性增长，消耗空间非常大，文本模型会面临稀疏问题，模型会欠稳定。
            SVD降维：对共现矩阵降维（相当于将一个大矩阵转换成小的矩阵相乘）
                  优点：降低共现矩阵的维度
                  缺点：计算量随着语料和词典增长太快，难以为词典新加入的词分配词向量，与其他深度学习模型框架差异大
            语言模型：一句话（词组合）出现的最大概率。或衡量一句话出现的合理性。
            NNLM(Neural Network Language model)：直接从语言模型出发，将模型最优化过程转化为求向量表示的过程
            Word2Vec：通过学习文本用词向量的方式表征的词语信息，即通过一个嵌入空间是的与以上相似的单词在该空间距离很近。
            Word2vec：CBOW(通过上下文确定该词的意思)








