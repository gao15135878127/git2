日志
1、Docker安装与使用 90%
2、安装CentOS 7 100%
3、文本表示： 
	不将文本视为字符串，而视为在数学上处理起来更为方便的向量。
	而怎么把字符串变为向量，就是文本表示的核心问题。
      读取语料，建立字典，每个单词都有唯一索引，在词典中的的顺序和在句子中的顺序没有关联。
    离散型表示：
      Bag of Words:100%
	词袋子模型：
	     是描述文档中单词出现的文本的一种表示形式，已知词汇的集合，测试已知单词的存在。
	 优点：简单、方便、快速；在预料充足的前提下，对于简单的自然语言处理任务效果不错。
	 缺点：1、准确率较低，对文本中的词一视同仁，不能体现不同词在一句话中的不同的重要性。
	       2、无法关注词语之间的顺序关系。
      One-hot表示：100%
	One-hot表示，每个单词在出存在字典中显示1，不存在的显示0。
	优点：解决了分类器不好处理离散数据的问题
	缺点：1、它是一个词袋模型，不考虑词与词之间的顺序。
	      2、它得到的特征是离散稀疏的。
      TF-IDF：90%
	文档的向量表示直接将各词的词向量表示加和。
	统计每个词出现的词频（TF），然后附上一个权值参数
	TF（词频） = 某个词在文章中的出现次数/文章的总次数
	IDF（逆文档频率） = log(语料库的文档总数/包含该词的文档数+1)
	TF - IDF = TF * IDF
	优点：简单快速，结果比较符合实际
	缺点：单纯考虑词频，忽略了词与词的位置信息以及词与词之间的相互关系。
      Bi-gram和N-gram：
	N-gram:
	  N-gram正是基于这样的想法，它的第一个特点是某个词的出现依赖于其他若干个词，第二个		特点是我们获得的信息越多，预测越准确。
      离散型表示存在的问题：
	无法衡量词向量之间的关系。
	词表的维度随着语料库的增长而膨胀。
	n-gram词序列随语料库增长呈指数型膨胀，更加快。
	离散数据来表示文本会带来数据稀疏问题，导致丢失了信息，与我们生活中理解的信息是不一样的
    分布式表示：
      用一个词附近的其他词来表示该词，是现代统计自然语言处理中最有创见的想法之一。
	共现矩阵（word-word）：80%
	  将共现矩阵行列作为词向量
	  向量维数随着词典大小线性增长
	  存储整个词典的空间消耗非常大
	  一些模型如文本分类模型会面临稀疏性问题
	  模型会欠稳定














